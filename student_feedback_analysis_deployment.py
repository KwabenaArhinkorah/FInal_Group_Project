# -*- coding: utf-8 -*-
"""Student Feedback Analysis deployment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rdArvKH_c0ZHu7YQSFXTeFXGtfgBCmiZ
"""

#install NeMo
from google.colab import drive
drive.mount('/content/drive')
BRANCH = 'main'
!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[nlp]

!pip install -q streamlit

from nemo.collections import nlp as nemo_nlp
from nemo.utils.exp_manager import exp_manager

import os
import streamlit as st
import wget
import torch
import pytorch_lightning as pl
from omegaconf import OmegaConf

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# 
# from nemo.collections import nlp as nemo_nlp
# from nemo.utils.exp_manager import exp_manager
# import os
# import wget
# import torch
# import pytorch_lightning as pl
# 
# # Define a function for sentiment prediction (placeholder)
# def predict_sentiment(text):
# 
#     model_path = '/content/drive/My Drive/ColabAssign/trained-model.nemo' #change to reflect your model
# 
#     model = nemo_nlp.models.TextClassificationModel.restore_from(restore_path=model_path)
# 
#     pred_dict = {0: 'Neutral', 1: 'Positive', 2: 'Negative'}
# 
#     if torch.cuda.is_available():
#         model.to("cuda")
#     else:
#         model.to("cpu")
# 
#     # max_seq_length=512 is the maximum length BERT supports.
#     results = model.classifytext(queries=text, batch_size=3, max_seq_length=512)
# 
#     # Replace this with the actual model prediction logic
#     return pred_dict[results[0]] # Example
# 
# # Title and Introduction
# st.title("Student Feedback Review System")
# st.markdown("""
# This system revolutionizes how educational institutions collect and analyze student feedback.
# It leverages mobile technology, advanced analytics, and machine learning to provide insightful and data-driven feedback analysis.
# Your input is valuable in enhancing the quality of education.
# """)
# 
# # Feedback Input
# feedback = st.text_area("Enter your feedback here:")
# 
# # Submit Button
# if st.button('Submit Feedback'):
#     # Process the feedback
#     # (You'll need to integrate your model here to predict sentiment)
#     sentiment = predict_sentiment(feedback)  # Replace with your model function
#     st.write("Predicted Sentiment Feedback:", sentiment)
# 
#

!npm install localtunnel

!streamlit run app.py &>/content/logs.txt &

!npx localtunnel --port 8501 & curl ipv4.icanhazip.com